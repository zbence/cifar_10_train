{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from IPython.display import Image \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2_with_const1s(nn.Module):\n",
    "     def __init__(self):\n",
    "        super(MobileNetV2_with_const1s, self).__init__()\n",
    "        \n",
    "        #Number of classes that the model will predict\n",
    "        self.out_feature_num = 4\n",
    "        \n",
    "        #load default pytorch mobilenetv2 model without ImageNet pretrained weights\n",
    "        #the Imagenet weights are not compatible with the 32x32 cifar10 images\n",
    "        self.mobilenetv2 = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=False)\n",
    "        self.mobilenetv2.eval()\n",
    "        \n",
    "        #modify the last dense layer to omit values for every available class\n",
    "        self.mobilenetv2.classifier[1] = nn.Linear(in_features=1280, out_features=self.out_feature_num, bias=True)\n",
    "        \n",
    "        \n",
    "     def forward(self, input):\n",
    "        mobile_out =self.mobilenetv2(input)\n",
    "        \n",
    "        #return the constant 1 array with the same shape as the last dense layer\n",
    "        dummy1s = [1] * self.out_feature_num\n",
    "        \n",
    "        return mobile_out, dummy1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2 = MobileNetV2_with_const1s()\n",
    "mobilenetv2.eval()\n",
    "\n",
    "\n",
    "mobilenetv2.mobilenetv2.features[0][0] = nn.Conv2d(3,32,kernel_size=(3, 3), stride=(1,1), padding=(1,1), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model with dummy data\n",
    "test = torch.ones([1,3,224, 224], dtype=torch.float)\n",
    "print(mobilenetv2(test), mobilenetv2.forward(test))\n",
    "\n",
    "mobilenetv2 = mobilenetv2.train()\n",
    "mobilenetv2.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loader class for the cifar 10 dataset\n",
    "class Ciffar(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "#Transform it to [0,1], then normalize every channel accordingly\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset and test if is it in the right shape\n",
    "X = None\n",
    "Y = None\n",
    "\n",
    "cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "with open(\"train_set\", \"rb\") as f:\n",
    "    d = pickle.load(f, encoding=\"bytes\")\n",
    "    X = d[b\"data\"].astype(float)/255\n",
    "    Y = d[b\"labels\"].astype(int)\n",
    "    \n",
    "X = X.reshape(1000, 3, 32,32)\n",
    "print(X.shape)\n",
    "train_data = Ciffar(X,Y, preprocess)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "X_test = None\n",
    "Y_test = None\n",
    "\n",
    "with open(\"test_set\", \"rb\") as f:\n",
    "    d = pickle.load(f, encoding=\"bytes\")\n",
    "    X_test = d[b\"data\"].astype(float)/255\n",
    "    Y_test = d[b\"labels\"].astype(int)\n",
    "    \n",
    "X_test = X_test.reshape(1000, 3, 32,32)\n",
    "test_data = Ciffar(X_test,Y_test, preprocess)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "for b,l in test_loader:\n",
    "    print(\"Test data shape\", b[0].shape)\n",
    "    break\n",
    "    \n",
    "for b,l in test_loader:\n",
    "    print(\"Train b[0].shape\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test if the test dataset contains the image data\n",
    "data_id = 0\n",
    "plt.imshow(X_test[data_id].transpose(1,2,0))\n",
    "\n",
    "print(cifar_classes[Y_test[data_id]])\n",
    "\n",
    "print(X_test[data_id].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test if the train dataset contains the image data\n",
    "data_id = 0\n",
    "plt.imshow(X[data_id].transpose(1,2,0))\n",
    "print(cifar_classes[Y[data_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Using a simple SGD to optimize\n",
    "optimizer = torch.optim.SGD(mobilenetv2.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "\n",
    "#Learning rate decay is exponential\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)\n",
    "\n",
    "\n",
    "max_epoch = 30\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    mobilenetv2.to(device)\n",
    "\n",
    "#This is a tensor which will be used to calculate accuracy over the batch\n",
    "y_onehot = torch.cuda.FloatTensor(16,4)    \n",
    "\n",
    "\n",
    "#List for storing metrics during the train session\n",
    "test_metrics = []\n",
    "train_metrics = []\n",
    "    \n",
    "for epoch in range(max_epoch):\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    \n",
    "    iter_count = 0\n",
    "    loss_acc = 0\n",
    "    accuracy_acc = 0\n",
    "    \n",
    "    test_metrics.append([])\n",
    "    train_metrics.append([])\n",
    "    \n",
    "    \n",
    "    #Train for 1 epoch\n",
    "    for local_batch, local_labels in train_loader:\n",
    "        mobilenetv2.train()\n",
    "        \n",
    "                \n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = mobilenetv2(local_batch)[0]\n",
    "        loss = criterion(output, local_labels)\n",
    "        \n",
    "        loss_acc += loss.data.item() / output.size(0)\n",
    "        \n",
    "        accuracy_acc += torch.eq(torch.argmax(torch.nn.Softmax(dim=1)(output), dim=1), local_labels).sum()  \\\n",
    "            / float(output.size(0))\n",
    "\n",
    "        if iter_count % 10 == 0 and iter_count > 0:\n",
    "             \n",
    "            print(\"Iter\", iter_count, \" train loss:\", loss_acc/10)\n",
    "            \n",
    "            \n",
    "            print(\"Accuracy: \", accuracy_acc.item()/10)\n",
    "           \n",
    "            \n",
    "            \n",
    "            train_metrics[-1].append((loss_acc/10, accuracy_acc/10))\n",
    "            \n",
    "            accuracy_acc = 0\n",
    "            loss_acc = 0\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter_count += 1\n",
    "        \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        mobilenetv2.eval()\n",
    "        test_loss = 0\n",
    "        \n",
    "        test_accuracy = 0 \n",
    "        \n",
    "        iter_size = 0\n",
    "        for local_batch, local_labels in test_loader:\n",
    "            iter_size =+1\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "            \n",
    "         \n",
    "            output = mobilenetv2(local_batch)[0]\n",
    "            \n",
    "            loss = criterion(output, local_labels)\n",
    "            test_loss += loss.data.item() / output.size(0)\n",
    "            \n",
    "            test_accuracy += torch.eq(torch.argmax(torch.nn.Softmax(dim=1)(output), dim=1), local_labels).sum()  \\\n",
    "                / float(output.size(0))\n",
    "        print(\"Test loss:\", test_loss/len(test_loader))\n",
    "        print(\"Test accuracy\", test_accuracy.item()/len(test_loader))\n",
    "        test_metrics[-1].append((test_loss/len(test_loader), test_accuracy/len(test_loader )))\n",
    "        \n",
    "        \n",
    "        #Save the models under the models dir\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        torch.save(mobilenetv2.state_dict(), \"models/mobilenetv2_\" + str(epoch) + \".pt\")\n",
    "\n",
    "         \n",
    "        \n",
    "        \n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"lr\", param_group['lr'])\n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss and test accuracy. As we can see on the test set it's not converging to optima all the time, it's drifting away from the optimal solution because the model is overfitting on the small train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(test_metrics)), list(map(lambda x: x[0],test_metrics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_metrics)), list(map(lambda x: x[0],train_metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
